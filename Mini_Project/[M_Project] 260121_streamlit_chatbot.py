import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
model = "gpt-4o-mini"

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=OPENAI_API_KEY)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="centered"
)

# ì œëª©
st.title("ğŸ¤– GPT-4o Mini ì±—ë´‡")
st.caption("OpenAI GPT-4o Miniì™€ ëŒ€í™”í•´ë³´ì„¸ìš”!")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# OpenAI APIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(messages):
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.7,
            max_tokens=1000,
            stream=True  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
        )
        return response
    except Exception as e:
        return None

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # ë´‡ ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # OpenAI API í˜¸ì¶œ
        response_stream = generate_response(st.session_state.messages)
        
        if response_stream:
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
            for chunk in response_stream:
                if chunk.choices[0].delta.content is not None:
                    full_response += chunk.choices[0].delta.content
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
        else:
            full_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            message_placeholder.markdown(full_response)
    
    # ë´‡ ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": full_response})

# ì‚¬ì´ë“œë°”ì— ì¶”ê°€ ì •ë³´
with st.sidebar:
    st.header("â„¹ï¸ ì •ë³´")
    st.write("ì´ ì±—ë´‡ì€ OpenAI GPT-4o Minië¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    st.header("âš™ï¸ ì„¤ì •")
    
    # API í‚¤ ìƒíƒœ í™•ì¸
    if OPENAI_API_KEY:
        st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.error("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.info("`.env` íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    
    st.write(f"**ëª¨ë¸:** {model}")
    
    st.header("ğŸ“Š í†µê³„")
    st.write(f"ëŒ€í™” ë©”ì‹œì§€ ìˆ˜: {len(st.session_state.messages)}")
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì • (ì„ íƒì‚¬í•­)
    with st.expander("ğŸ¨ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •"):
        system_prompt = st.text_area(
            "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
            value="ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.",
            help="ì±—ë´‡ì˜ ì„±ê²©ê³¼ ì—­í• ì„ ì •ì˜í•©ë‹ˆë‹¤."
        )
        
        if st.button("ì ìš©"):
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            if not st.session_state.messages or st.session_state.messages[0]["role"] != "system":
                st.session_state.messages.insert(0, {"role": "system", "content": system_prompt})
            else:
                st.session_state.messages[0]["content"] = system_prompt
            st.success("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    
    st.caption("ğŸ’¡ Powered by OpenAI GPT-4o Mini")

# ëª…ë ¹ì–´ëŠ” streamlit run streamlit_chatbot.py